# Machine Learning and Data Science

This repository contains some of my work in the fields of Machine Learning and Data Science.

The notebooks are experiments, courses, kaggle entries, hacks and code ideas from various sources.  The work was done in python utilising numpy, pandas and scikit-learn.  For most of these notebooks I have used the following sources as my starting point:

[Udacity](https://eu.udacity.com/) &nbsp; 
[Coursera](https://www.coursera.org) &nbsp; 
[Kaggle](https://www.kaggle.com) &nbsp; 
[Sebastian Raschka](https://sebastianraschka.com/books.html) &nbsp; 
[Jason Brownlee](https://machinelearningmastery.com) &nbsp; 
[Sebastian Ruder](http://ruder.io/optimizing-gradient-descent/) &nbsp; 
[Kevin Markham](https://www.youtube.com/user/dataschool) &nbsp; 


## Notebooks
* [Donor Screening on Kaggle](https://github.com/riched158/Kaggle/blob/master/P1/donors1.ipynb): Kaggle entry on Donors Screening
* [Advanced Regression Techniques](https://github.com/riched158/Kaggle/blob/master/P1/Ames_Housing1.ipynb): Exploratory Data Analysis and Regression techniques to predict houseprices.
* [SKLearn Model Comparison](https://github.com/riched158/MachineLearning/blob/master/Binary%20Classification.ipynb): Trying different models on a binary classification problem
* [Transforming Features](https://github.com/riched158/Machine-Learning-Shallow/blob/master/FeaturesAndTransformers.ipynb): Transforming data with SciKit Learn.
* [Titanic Prediction](https://github.com/riched158/MachineLearning/blob/master/TitanicPipelines.ipynb): Using Transforms and Ensemble methods to predict Titanic survival
* [EDA on Titanic Dataset](https://github.com/riched158/Kaggle/blob/master/P1/Titanic4.ipynb): Exploratory Data Analysis on the Titanic Kaggle Dataset
* [Affinity Analysis](https://github.com/riched158/MachineLearning/blob/master/AffinityAnalysis.ipynb): Utilise Affinity analysis on the MovieLens 100k dataset.
* [Decision Trees](https://github.com/riched158/MachineLearning/blob/master/DTs_and_Feature_Engineeering.ipynb): Predicting NBA winners with Decision Tree based methods.
* [Internet Advertisement Detection](https://github.com/riched158/MachineLearning/blob/master/FeaturesAndTransformers2.ipynb): Predicting adverts on on internet using Decision Trees
* [KNN](https://github.com/riched158/MachineLearning/blob/master/KNN.ipynb): K-Nearest Neighbours investigation of dataset with SciKit Learn 
* [XGBoost](https://github.com/riched158/MachineLearning/blob/master/XGBoostTutorial.ipynb): Using Gradient Boosting on Facebook Dataset
* [Bagging](https://github.com/riched158/MachineLearning/blob/master/Bagging%20Regressor.ipynb): Simple experiment with bagging regressor 
* [Gradient Descent](https://github.com/riched158/ML-Regression/blob/master/week-2-multiple-regression-assign-2.ipynb): University of Washington Coursera assignment on Gradient Descent.
* [Polynomial Regression](https://github.com/riched158/ML-Regression/blob/master/week-3-polynomial-regression-assign.ipynb): University of Washington Coursera assignment on Polynomial Regression.
* [Ridge and Lasso Regression](https://github.com/riched158/ML-Regression/blob/master/Overfitting_Ridge_Lasso.ipynb): University of Washington Coursera assignment on Ridge and Lasso Regression.
* [Lasso Regularisation](https://github.com/riched158/ML-Regression/blob/master/week-5-lasso-assign-2.ipynb): University of Washington Coursera assignment on Lasso.
* [Regression Models](https://github.com/riched158/MachineLearning/blob/master/RegressionModels.ipynb): Evaluating various machine learning algorithms on a dataset



